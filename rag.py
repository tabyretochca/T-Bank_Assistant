import redis
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms import HuggingFacePipeline
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig

class RAGSystem:
    def __init__(self, chroma_dir="./chroma_db"):
        # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏
        self.embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
        # –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞
        self.vectorstore = Chroma(persist_directory=chroma_dir, embedding_function=self.embeddings)
        # Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        self.redis_client = redis.Redis(host="localhost", port=6379, db=0)
        # –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        self.llm = None

    def load_llm(self):
        # –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –¥–ª—è ruGPT-3.5 
        quantization_config = BitsAndBytesConfig(load_in_4bit=True)
        tokenizer = AutoTokenizer.from_pretrained("ai-forever/ruGPT-3.5")
        model = AutoModelForCausalLM.from_pretrained("ai-forever/ruGPT-3.5", quantization_config=quantization_config)
        pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=50)
        self.llm = HuggingFacePipeline(pipeline=pipe)

    def format_response(self, raw_answer, source):
        return f"üìã –û—Ç–≤–µ—Ç: {raw_answer}\nüîó –ò—Å—Ç–æ—á–Ω–∏–∫: {source}\n–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –Ω–∞–ø–∏—à–∏—Ç–µ!"

    def get_response(self, query, use_llm=False):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached = self.redis_client.get(query)
        if cached:
            return cached.decode(), self.get_buttons(query)

        # –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        docs = self.vectorstore.similarity_search(query, k=1)
        if not docs:
            response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ –Ω–∞—à—ë–ª –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å."
            return response, self.get_buttons(query)

        context = docs[0].page_content
        answer = context.split("–û—Ç–≤–µ—Ç: ")[1] if "–û—Ç–≤–µ—Ç: " in context else context
        source = docs[0].metadata["source"]

        # –ï—Å–ª–∏ LLM –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è (–ª–æ–∫–∞–ª—å–Ω–æ)
        if not use_llm or not self.llm:
            response = self.format_response(answer, source)
            self.redis_client.set(query, response)
            return response, self.get_buttons(query)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å LLM 
        prompt = f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞:\n{context}\n–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: {query}\n–î–æ–±–∞–≤—å: –ò—Å—Ç–æ—á–Ω–∏–∫: {source}"
        response = self.llm(prompt)
        formatted_response = self.format_response(response, source)
        self.redis_client.set(query, formatted_response)
        return formatted_response, self.get_buttons(query)

    def get_buttons(self, query):
        buttons = [
            {"text": "–û—Ç–∫—Ä—ã—Ç—å —Å—á—ë—Ç", "url": "https://tbank.ru/kassa/form/partner/"},
            {"text": "–°–≤—è–∑–∞—Ç—å—Å—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π", "url": "https://tbank.ru/support/"}
        ]
        if "–ª–∏–º–∏—Ç" in query.lower():
            buttons.append({"text": "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–∏–º–∏—Ç—ã", "url": "https://tbank.ru/app/check-limits"})
        return buttons